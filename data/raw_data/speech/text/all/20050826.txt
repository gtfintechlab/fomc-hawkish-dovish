The Federal Reserve System was created in 1913 to counter the recurrent credit stringencies that had so frequently been experienced in earlier decades.
As lender of last resort, we had a mandate that, at least viewed from today's perspective, was limited.
We did not engage in Systemwide open market operations until the 1920s.
And as recently as the 1950s, the framework within which those open market operations were formulated was still being developed.
Credit was eased when the economy weakened and tightened when inflation threatened, but largely in an ad hoc manner.
As a consequence, the Federal Reserve was perceived by some as often accentuating, rather than damping, cycles in prices and activity.
Importantly, however, the surge in prices that followed the removal of wage and price controls after World War II and again after the Korean War kept monetary policymakers wary of the threat of inflation.
But concern that the monetary restraint of the 1950s had led to unnecessarily high unemployment persuaded the Federal Open Market Committee to adopt a more stimulative policy stance in the mid-1960s.
Those actions appear to have been predicated, in part, on an acceptance of the then-prevalent view that a long-term tradeoff existed between inflation and unemployment.1 Subsequently, however, the experience of stagflation in the 1970s and intellectual advances in understanding the importance of expectations--which built on the earlier work of Friedman and Phelps--undermined the notion of a long-run tradeoff.2 Inflation again became widely viewed as being detrimental to financial stability and macroeconomic performance.
And as the decade progressed, a keener appreciation for the monetary roots of inflation emerged both in the profession at large and at central banks.
Indeed, the insights from the work of Friedman and Schwartz a decade earlier gained greater prominence in the realm of practical policy.3 These events, both economic and intellectual, significantly influenced the tool kits employed by macroeconomists inside and outside policymaking institutions.
The large-scale macromodels that had been the focus of so much work in the 1960s came under attack on two fronts.
Most prominently, greater recognition of the importance of expectations suggested that those models, which for the most part incorporated autoregressive expectations, were excessively reduced-form and backward-looking in nature and thus insensitive to changes in economic structure and the policy process.
In addition, some researchers observed that simple time-series models often produced better forecasts than the large macromodels of that period.4 One prescription was to focus on uncovering, at a more fundamental level, the structural parameters of the economy.
Needless to say, this task has proven to be a very tall order that has yet to be filled.
Partly in response to these difficulties, a substantial body of research focused on improvements in empirical modeling, such as vector autoregressions for forecasting, and in some cases, for policy analysis.
Each one of these approaches has proven useful, and their descendants are currently employed in various forms in central banks throughout the world.
But as yet, none of these approaches is capable of addressing the full range of policymakers' needs.
At various points in time, some analysts have held out hope that a single indicator variable--such as commodity prices, the yield curve, nominal income, and of course, the monetary aggregates--could be used to reliably guide the conduct of monetary policy.
If it were the case that an indicator variable or a relatively simple equation could extract the essence of key economic relationships from an exceedingly complex and dynamic real world, then broader issues of economic causality could be set aside, and the tools of policy could be directed at fostering a path for this variable consistent with the attainment of the ultimate policy objective.
M1 was the focus of policy for a brief period in the late 1970s and early 1980s.
That episode proved key to breaking the inflation spiral that had developed over the 1970s, but policymakers soon came to question the viability over the longer haul of targeting the monetary aggregates.
The relationships of the monetary aggregates to income and prices were eroded significantly over the course of the 1980s and into the early 1990s by financial deregulation, innovation, and globalization.
For example, the previously stable relationship of M2 to nominal gross domestic product and the opportunity cost of holding M2 deposits underwent a major structural shift in the early 1990s because of the increasing prevalence of competing forms of intermediation and financial instruments.
In the absence of a single variable, or at most a few, that can serve as a reliable guide, policymakers have been forced to fall back on an approach that entails the interpretation of the full range of economic and financial data.
Policy is implemented through nominal and, implicitly, real short-term interest rates.
However, reflecting the progress in economic understanding, our actions are now better informed about the pitfalls associated with relying on nominal interest rates to set policy and the important role played by inflation expectations in gauging the stance of monetary policy.
Our appreciation of the importance of expectations has also shaped our increasing transparency about policy actions and their rationale.
We have moved toward greater transparency at a "measured pace" in part because we were concerned about potential feedback on the policy process and about being misinterpreted--as indeed we were from time to time.
I do not intend this brief and necessarily incomplete review of events to illustrate how far we have come or to despair of how far we have to go.
Rather, I believe it demonstrates the inevitable and ongoing uncertainty faced by policymakers.
Despite extensive efforts to capture and quantify what we perceive as the key macroeconomic relationships, our knowledge about many critical linkages is far from complete and, in all likelihood, will remain so.
Every model, no matter how detailed or how well conceived, designed, and implemented, is a vastly simplified representation of the world, with all of the intricacies we experience on a day-to-day basis.
Formal models are a necessary, but not sufficient, system of analysis.
To be sure, models discipline forecasts by requiring, among many restraints, that identities are indeed equal, inventories non-negative, and marginal propensities to consume positive.
But we all temper the outputs of our models and test their results against the ongoing evaluations of a whole array of observations that we do not capture in either the data input or the structure of our models.
We are particularly sensitive to observations that appear inconsistent with the causal relationships of our formal models.
Tentative revisions of that structure are reflected in our add factors.
Given our inevitably incomplete knowledge about key structural aspects of an ever-changing economy and the sometimes asymmetric costs or benefits of particular outcomes, the paradigm on which we have settled has come to involve, at its core, crucial elements of risk management.
In this approach, a central bank needs to consider not only the most likely future path for the economy but also the distribution of possible outcomes about that path.
The decisionmakers then need to reach a judgment about the probabilities, costs, and benefits of various possible outcomes under alternative choices for policy.
The risk-management approach has gained greater traction as a consequence of the step-up in globalization and the technological changes of the 1990s, which found us adjusting to events without the comfort of relevant history to guide us.
Forecasts of change in the global economic structure--for that is what we are now required to construct--can usefully be described only in probabalistic terms.
In other words, point forecasts need to be supplemented by a clear understanding of the nature and magnitude of the risks that surround them.
In effect, we strive to construct a spectrum of forecasts from which, at least conceptually, specific policy action is determined through the tradeoffs implied by a loss-function.
In the summer of 2003, for example, the Federal Open Market Committee viewed as very small the probability that the then-gradual decline in inflation would accelerate into a more consequential deflation.
But because the implications for the economy were so dire should that scenario play out, we chose to counter it with unusually low interest rates.
The product of a low-probability event and a potentially severe outcome was judged a more serious threat to economic performance than the higher inflation that might ensue in the more probable scenario.
Moreover, the risk of a sizable jump in inflation seemed limited at the time, largely because increased productivity growth was resulting in only modest advances in unit labor costs and because heightened competition, driven by globalization, was limiting employers' ability to pass through those cost increases into prices.
Given the potentially severe consequences of deflation, the expected benefits of the unusual policy action were judged to outweigh its expected costs.
* * * The structure of our economy will doubtless change in the years ahead.
In particular, our analysis of economic developments almost surely will need to deal in greater detail with balance sheet considerations than was the case in the earlier decades of the postwar period.
The determination of global economic activity in recent years has been influenced importantly by capital gains on various types of assets, and the liabilities that finance them.
Our forecasts and hence policy are becoming increasingly driven by asset price changes.
The steep rise in the ratio of household net worth to disposable income in the mid-1990s, after a half-century of stability, is a case in point.
Although the ratio fell with the collapse of equity prices in 2000, it has rebounded noticeably over the past couple of years, reflecting the rise in the prices of equities and houses.
Whether the currently elevated level of the wealth-to-income ratio will be sustained in the longer run remains to be seen.
But arguably, the growing stability of the world economy over the past decade may have encouraged investors to accept increasingly lower levels of compensation for risk.
They are exhibiting a seeming willingness to project stability and commit over an ever more extended time horizon.
The lowered risk premiums--the apparent consequence of a long period of economic stability--coupled with greater productivity growth have propelled asset prices higher.5 The rising prices of stocks, bonds and, more recently, of homes, have engendered a large increase in the market value of claims which, when converted to cash, are a source of purchasing power.
Financial intermediaries, of course, routinely convert capital gains in stocks, bonds, and homes into cash for businesses and households to facilitate purchase transactions.6 The conversions have been markedly facilitated by the financial innovation that has greatly reduced the cost of such transactions.
Thus, this vast increase in the market value of asset claims is in part the indirect result of investors accepting lower compensation for risk.
Such an increase in market value is too often viewed by market participants as structural and permanent.
To some extent, those higher values may be reflecting the increased flexibility and resilience of our economy.
But what they perceive as newly abundant liquidity can readily disappear.
Any onset of increased investor caution elevates risk premiums and, as a consequence, lowers asset values and promotes the liquidation of the debt that supported higher asset prices.
This is the reason that history has not dealt kindly with the aftermath of protracted periods of low risk premiums.
* * * Broad economic forces are continuously at work, shaping the environment in which the Federal Reserve makes monetary policy.
In recent years, the U.S. economy has prospered notably from the increase in productivity growth that began in the mid-1990s and the enhanced competition engendered by globalization.
Innovation, spurred by competition, has nurtured the continual scrapping of old technologies to make way for the new.
Standards of living have risen because depreciation and other cash flows generated by industries employing older, increasingly obsolescent technologies have been reinvested to finance newly produced capital assets that embody cutting-edge technologies.
But there is also no doubt that this transition to the new high-tech economy, of which expanding global trade is a part, is proving difficult for a segment of our workforce that interfaces day by day with our rapidly changing capital stock.
This difficulty is most evident in the increased fear of job-skill obsolescence that has induced significant numbers of our population to resist the competitive pressures inherent in globalization from workers in the major newly emerging market economies.
It is important that these understandable fears be addressed through education and training and not by restraining the competitive forces that are so essential to overall rising standards of living of the great majority of our population.
A fear of the changes necessary for economic progress is all too evident in the current stymieing of international trade negotiations.
Fear of change is also reflected in a hesitancy to face up to the difficult choices that will be required to resolve our looming fiscal problems.
The developing protectionism regarding trade and our reluctance to place fiscal policy on a more sustainable path are threatening what may well be our most valued policy asset: the increased flexibility of our economy, which has fostered our extraordinary resilience to shocks.
If we can maintain an adequate degree of flexibility, some of America's economic imbalances, most notably the large current account deficit and the housing boom, can be rectified by adjustments in prices, interest rates, and exchange rates rather than through more-wrenching changes in output, incomes, and employment.
The more flexible an economy, the greater its ability to self-correct in response to inevitable, often unanticipated, disturbances.
That process of correction limits the size and the consequences of cyclical imbalances.
Enhanced flexibility provides the advantage of allowing the economy to adjust automatically, reducing the reliance on the actions of monetary and other policymakers, which have often come too late or been misguided.
In fact, the performance of the U.S. economy in recent years, despite shocks that in the past would have surely produced marked economic contraction, offers the clearest evidence that we have benefited from an enhanced resilience and flexibility.
We weathered a decline on October 19, 1987 of a fifth of the market value of U.S. equities with little evidence of subsequent macroeconomic stress--an episode that provided an early hint that adjustment dynamics might be changing.
The credit crunch of the early 1990s and the bursting of the stock market bubble in 2000 were absorbed with the shallowest recessions in the post-World War II period.
And the economic fallout from the tragic events of September 11, 2001, was limited by market forces, with severe economic weakness evident for only a few weeks.
Most recently, the flexibility of our market-driven economy has allowed us, thus far, to weather reasonably well the steep rise in spot and futures prices for crude oil and natural gas that we have experienced over the past two years.
* * * This morning I have tried to outline my perceptions of the key developments that have influenced the conduct of monetary policy over the past eighteen years.
I acknowledge that monetary policy itself has been an important contributor to the decline in inflation and inflation expectations over the past quarter-century.
Indeed, the Federal Reserve under Paul Volcker's leadership starting in 1979 did the very heavy lifting against inflation.
