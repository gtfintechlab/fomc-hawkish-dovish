The past decade or so has been marked by a remarkable surge in technological innovation and business efficiency.
This period of rapid innovation has brought with it enormous opportunities to enhance living standards for a large majority of Americans.
Our ability to take full advantage of these opportunities depends crucially on how well we as a nation can integrate these new technologies into our society.
In my remarks today, I would like to offer some perspective on the challenges created by the interaction of new technologies with the skills of the American workforce, and how the educational system has in the past and can in the future respond to these challenges.
The process of innovation is, of course, never ending.
Over the past 100 years, for example, the rate of increase of the gross domestic product of the United States, adjusted for price change, has averaged around 3 percent per year.
Yet only a fraction of that increase represents growth in the tonnage of physical materials--particularly oil, coal, wood, raw chemicals--and increases in the amount of manual labor employed in the production process.
The remainder represents new value-adding insights into how to rearrange physical materials and labor inputs to better serve human needs--in short, the conceptual content of the GDP.
The inexorably rising share of the nation’s output that is conceptual appears to have accelerated following World War II with the insights that led to the development of the transistor, microprocessor, laser, and fiber optic technologies.
By the 1990s, these and other critical innovations had fostered an enormous new capacity to capture, analyze, and disseminate information and had begun to alter significantly how we do business and create economic value, often in ways that were not foreseeable even a decade ago.
Indeed, it is the proliferation of information technology throughout the economy that makes the current period so special.
The types of skills needed to interact with the new methods of adding value associated with this diffusion of information technologies are complex.
One obviously needs a core of highly skilled workers to push the frontier of technology forward and to make the newer technologies more accessible to the rest of the workforce.
Once technology becomes more user friendly, the ability of the general workforce to create value is greatly facilitated.
What is particularly telling in this regard is how well the American economy has performed with a workforce for which the average level of education has been roughly unchanged for a quarter of a century.
As labor markets tightened in the mid-1990s, the anecdotal reports of worker shortages were worrisome.
There were numerous stories of employers going through entire lists of people before finding someone who could do the job, and widespread concerns that a lack of high-tech skills among American workers would prevent much of the population from participating fully in the economic gains associated with the emerging high-tech revolution.
Consistent with these anecdotes, in a national survey of small businesses, the percentage citing labor quality as their most important problem rose from less than 5 percent in 1993 to 20 percent by 1998.
As it turned out, however, the capacity for American businesses to absorb the less educated part of our workforce seems to have been far greater than these anecdotes implied.
The unemployment rate for adults with a high school education or less fell from 4¾ percent in 1998 to around 4 percent by the middle of last year.
And, while the proportion of small-business managers who worried about labor quality has remained elevated in the past few years, it did not increase further in spite of the decline in unemployment.
One explanation for this phenomenon is the often-observed multiplier effects of technological breakthroughs.
For example, as engineers and programmers have developed increasingly more sophisticated hardware and software, the vast productive benefits of computers have become far more readily available to the average worker in recent years.
Looking back a number of decades to the early stages of the information technology revolution, we can see that COBOL and Fortran were the “visas” into the world of technology.
Those workers without very sophisticated programming skills could not interface with the new computer-driven technologies and thus often could not take advantage of the potential productivity improvements associated with those technologies.
But today’s increasingly user-friendly software has enabled workers with far less education and skills to engender value added from new technologies that their older brothers and sisters could not have foreseen a half generation earlier.
In particular, we are finding that despite the awesome capabilities of our newer innovations, there are certain skills inherent in all human beings that technology cannot replicate.
Low-skilled workers in decades past had to rely principally on their manual labor skills to create value added.
Today, the newer technologies give similarly skilled workers the opportunity to vastly multiply their value-producing capabilities by leveraging their ability to identify and classify.
For example, retail sales clerks not only facilitate sales in the conventional manner, but also automatically engender books of account, inventory control, and supplier reorders.
But, while software has increased our capacity to integrate lower-skilled individuals into the workforce, the rapidity and unpredictability of innovation also imply a need to strengthen those cognitive skills of our overall workforce.
An increasing proportion of the workforce must be equipped not simply with technical know-how, but also with the ability to create, analyze, and transform information and to effectively interact electronically with others.
Moreover, learning will increasingly need to be a lifelong activity.
The days when a high school or college education would serve a graduate throughout his or her working career are gone.
Today's recipients of diplomas should expect to have many jobs and to acquire and use an ever-expanding range of skills over their working lives.
It may not seem credible that an educational system shown by many studies to stifle learning between the fourth and twelfth grades relative to the systems of our foreign trading partners can provide our workforce with the necessary intellectual tools going forward.
But, while such studies suggest there is much to be done, there also are reasons to be optimistic.
In the past, our educational system, defined in its widest sense, has been guided importantly by the marketplace toward the broader needs of our economy.
Indeed, the history of education in the United States traces a path heavily influenced by two themes: the need for a workforce with the skills required to interact productively with the evolving economic structure, and a thirst for knowledge among the American people.
The educational system during the early years of the United States was far less formalized than today.
There were, of course, grammar schools and colleges that catered to the wealthier segments of society.
But most individuals had little access to more than a minimal level of formal schooling because they were needed to work on the farm.
In 1800, for example, more than 90 percent of Americans lived on farms.
Yet, our ancestors understood the value of education, and less formal arrangements were frequently used; home-based schooling, private tutors, and church-sponsored Sunday schools are just a few examples.
The one-room schoolhouse on the prairie still provokes a remarkable, though perhaps not wholly justified, degree of nostalgia.
People felt that once a child learned how to read and write, an unlimited world opened up.
The focus in those early years was thus often on increasing literacy--beyond that, children were expected to read books to satisfy their interest in other subjects such as science or philosophy.
In this sense, the inquisitive nature of the people of that time drove the need to know beyond the measures of formal education in those early years.
Evidence of our ancestors’ intellectual capacity and desire to acquire a broader education are abundant.
Abraham Lincoln, for example, had little formal education while a young child, but once taught how to read by his mother, he read voraciously in a wide range of subjects.
And one can only marvel at the letters that twenty-year-old soldiers sent back home in the Civil War.
They were remarkably thoughtful and literate.
These soldiers, presumably with little formal education, were obviously reasonably well read.
They did have the advantage, of course, of a world without television.
Early in the twentieth century, advances in technology began to require workers with a higher level of cognitive skills, for instance the ability to read manuals, to interpret blueprints, or to understand formulas.
Our market-driven educational system responded: In the 1920s and 1930s, high school enrollment in this country expanded rapidly, pulling youth from rural areas, where opportunities were limited, into more productive occupations in business and broadening the skills of students to meet the needs of an advancing manufacturing sector.
At the same time, our system of higher education was also responding to the advances in economic processes.
Although many states had established land grant schools earlier, support for these schools accelerated in the late nineteenth century as institutions located in states that specialized in agriculture and mining sought to take advantage of new scientific methods of production.
A century ago, the content of education at an American college had evolved from a classically based curriculum to one combining the sciences, empirical studies, and modern liberal arts.
Universities responded to the need for the application of science--particularly chemistry and physics--to the manufacture of steel, rubber, chemicals, drugs, petroleum, and other goods requiring the newer production technologies.
Communities looked to their institutions of higher learning for leadership in scientific knowledge and for training of professionals such as teachers and engineers.
During this time, the scale and scope of higher education in America was shaped by the recognition that research--the creation of knowledge--complemented teaching and training--the diffusion of knowledge.
In broad terms, the basic structure of higher education remains much the same today, and it has been one that has proven sufficiently flexible to respond to the needs of a changing economy.
Certainly, if we are to remain preeminent in transforming knowledge into economic value, the U.S. system of higher education must remain the world leader in generating scientific and technological breakthroughs and in preparing workers to meet the evolving demands for skilled labor.
However, the pressure to enable all workers to benefit from the new technologies also requires that we strengthen the significant contributions of other types of training and educational programs, especially for those with lesser skills.
The notion that formal degree programs at any scholastic level or that any other training program established today can be crafted to fully support the requirements of one’s full working life has become subject to increasing doubt.
It is evident that we need to foster a flexible education system--one that integrates work and training and that serves the needs both of experienced workers at different stages in their careers and of students embarking on their initial course of study.
Community colleges, for example, have become important providers of job skills training not just for students who may eventually move on to a four-year college or university but for individuals with jobs--particularly workers seeking to retool, retrain, or simply to broaden their skills.
The increasing availability of courses that can be taken “at a distance” over the Internet means that learning can more easily occur outside the workplace or the classroom.
Economists have long argued that a significant proportion of the work knowledge that one acquires in a lifetime is produced on the job.
Several decades ago much of that on-the-job training was acquired through work experience.
Today, businesses and labor unions are placing greater emphasis on the value of formal education and training programs--ranging from corporate universities to partnerships with community colleges and other providers--as well as relationships with public agencies, including welfare-to-work and school-to-work programs.
These efforts recognize that technologically advanced learning must be grounded in real-world curriculums that are relevant to changing business needs and that it be provided in flexible venues that open access to development of skills to as many workers as possible.
Meeting the complex range of skills likely to be required of our workforce in the future presents a significant challenge to our educational system.
But it is a challenge we cannot afford to ignore.
